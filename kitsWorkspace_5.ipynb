{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderEfficientNetB5(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EncoderEfficientNetB5, self).__init__()\n",
    "        # Load EfficientNet-B5\n",
    "        self.encoder = EfficientNet.from_pretrained('efficientnet-b5') if pretrained else EfficientNet.from_name('efficientnet-b5')\n",
    "        # Extract blocks (stages)\n",
    "        self.blocks = self.encoder._blocks\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Store features from different stages\n",
    "        features = []\n",
    "        x = self.encoder._conv_stem(x)  # Initial convolution\n",
    "        x = self.encoder._bn0(x)       # Batch normalization\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            features.append(x)         # Save intermediate features\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderFPN(nn.Module):\n",
    "    def __init__(self, encoder_channels, decoder_channels):\n",
    "        super(DecoderFPN, self).__init__()\n",
    "        self.up_convs = nn.ModuleList()\n",
    "        self.lat_convs = nn.ModuleList()\n",
    "\n",
    "        # Build lateral and upsampling convolutions\n",
    "        for in_channels in encoder_channels:\n",
    "            self.lat_convs.append(nn.Conv2d(in_channels, decoder_channels, kernel_size=1))\n",
    "            self.up_convs.append(nn.Conv2d(decoder_channels, decoder_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "    def forward(self, encoder_features):\n",
    "        # Start from the deepest feature and go upwards\n",
    "        x = self.lat_convs[-1](encoder_features[-1])  # Lateral convolution for the deepest feature\n",
    "        outputs = [x]  # Collect outputs\n",
    "\n",
    "        # Iterate through the encoder features in reverse order\n",
    "        for i in range(len(encoder_features) - 2, -1, -1):\n",
    "            x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)  # Upsample\n",
    "            lateral = self.lat_convs[i](encoder_features[i])  # Apply lateral convolution\n",
    "            x = x + lateral  # Add lateral and upsampled feature\n",
    "            x = self.up_convs[i](x)  # Apply up convolution\n",
    "            outputs.append(x)\n",
    "        \n",
    "        return outputs[::-1]  # Reverse to match spatial resolution order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetFPN(nn.Module):\n",
    "    def __init__(self, num_classes, encoder_channels, decoder_channels=256):\n",
    "        super(EfficientNetFPN, self).__init__()\n",
    "        self.encoder = EncoderEfficientNetB5(pretrained=True)\n",
    "        self.decoder = DecoderFPN(encoder_channels, decoder_channels)\n",
    "        self.final_conv = nn.Conv2d(decoder_channels, num_classes, kernel_size=1)  # Final 1x1 convolution\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_features = self.encoder(x)\n",
    "        decoder_features = self.decoder(encoder_features)\n",
    "        x = decoder_features[0]  # Use the highest-resolution output\n",
    "        x = self.final_conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to C:\\Users\\PRAGNA/.cache\\torch\\hub\\checkpoints\\efficientnet-b5-b6417697.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "# Encoder channels for EfficientNet-B5\n",
    "encoder_channels = [48, 144, 240, 384, 2048]  # Output channels from each stage\n",
    "\n",
    "# Initialize the model\n",
    "model = EfficientNetFPN(num_classes=2, encoder_channels=encoder_channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BCEWithLogitsLossCustom(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCEWithLogitsLossCustom, self).__init__()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()  # Automatically applies sigmoid\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        return self.bce_loss(inputs, targets)\n",
    "\n",
    "# Example usage:\n",
    "# loss_fn = BCEWithLogitsLossCustom()\n",
    "# loss = loss_fn(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Flatten the inputs and targets\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # Compute BCE loss\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        \n",
    "        # Focal Loss modulation factor\n",
    "        pt = torch.exp(-bce_loss)  # Probability of the true class\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Example usage:\n",
    "# focal_loss = FocalLoss(alpha=0.25, gamma=2)\n",
    "# loss = focal_loss(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Apply sigmoid to inputs to get probabilities\n",
    "        inputs = torch.sigmoid(inputs).view(-1)  \n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        union = inputs.sum() + targets.sum()\n",
    "\n",
    "        dice_score = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice_score  # To minimize the Dice Loss\n",
    "\n",
    "# Example usage:\n",
    "# dice_loss = DiceLoss()\n",
    "# loss = dice_loss(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, smooth=1e-6):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss = DiceLoss(smooth)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce = self.bce_loss(inputs, targets)\n",
    "        dice = self.dice_loss(inputs, targets)\n",
    "        return bce + alpha * dice  # You can adjust the alpha weight as needed\n",
    "\n",
    "# Example usage:\n",
    "# loss_fn = DiceBCELoss(alpha=0.5)\n",
    "# loss = loss_fn(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2, smooth=1e-6):\n",
    "        super(DiceFocalLoss, self).__init__()\n",
    "        self.focal_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "        self.dice_loss = DiceLoss(smooth)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        focal = self.focal_loss(inputs, targets)\n",
    "        dice = self.dice_loss(inputs, targets)\n",
    "        return focal + dice  # You can adjust the weighting as needed\n",
    "\n",
    "# Example usage:\n",
    "# loss_fn = DiceFocalLoss(alpha=0.25, gamma=2)\n",
    "# loss = loss_fn(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(BCEFocalLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Flatten the inputs and targets\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # Compute BCE loss\n",
    "        bce_loss = self.bce_loss(inputs, targets)\n",
    "\n",
    "        # Compute Focal Loss modulation factor\n",
    "        pt = torch.exp(-bce_loss)  # Probability of the true class\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Example usage:\n",
    "# combined_loss = BCEFocalLoss(alpha=0.25, gamma=2)\n",
    "# loss = combined_loss(output, target)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
