{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class to handle image and mask loading\n",
    "class KidneySegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, mask_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "        self.case_folders = [folder for folder in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, folder))]\n",
    "        self.slice_counts = []\n",
    "        for case_id in self.case_folders:\n",
    "            case_image_dir = os.path.join(self.image_dir, case_id)\n",
    "            num_slices = len([f for f in os.listdir(case_image_dir) if f.endswith('.png')])\n",
    "            self.slice_counts.append(num_slices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.slice_counts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cumulative_slices = 0\n",
    "        for i, num_slices in enumerate(self.slice_counts):\n",
    "            cumulative_slices += num_slices\n",
    "            if idx < cumulative_slices:\n",
    "                case_id = self.case_folders[i]\n",
    "                slice_id = idx - (cumulative_slices - num_slices)\n",
    "                break\n",
    "\n",
    "        img_files = sorted([f for f in os.listdir(os.path.join(self.image_dir, case_id)) if f.endswith('.png')])\n",
    "        mask_files = sorted([f for f in os.listdir(os.path.join(self.mask_dir, case_id)) if f.endswith('.png')])\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, case_id, img_files[slice_id])\n",
    "        mask_path = os.path.join(self.mask_dir, case_id, mask_files[slice_id])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet-B5 Encoder\n",
    "class EfficientNetB5Encoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EfficientNetB5Encoder, self).__init__()\n",
    "        self.encoder = models.efficientnet_b5(weights='EfficientNet_B5_Weights.DEFAULT' if pretrained else None)\n",
    "        self.encoder = nn.Sequential(*list(self.encoder.children())[:-2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPN Decoder\n",
    "class FPNDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FPNDecoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        self.upsample = nn.Upsample(size=(512, 512), mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.upsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined EfficientNet-FPN model\n",
    "class EfficientNetFPN(nn.Module):\n",
    "    def __init__(self, out_channels=1, pretrained=True):\n",
    "        super(EfficientNetFPN, self).__init__()\n",
    "        self.encoder = EfficientNetB5Encoder(pretrained=pretrained)\n",
    "        self.decoder = FPNDecoder(in_channels=2048, out_channels=out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        return self.decoder(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def bce_loss(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with checkpointing and cross-validation\n",
    "def train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5, checkpoint_dir='checkpoints'):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    mask_transform = transforms.ToTensor()\n",
    "    dataset = KidneySegmentationDataset(image_dir, mask_dir, transform=transform, mask_transform=mask_transform)\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset), start=1):\n",
    "        print(f\"Training fold {fold}/{num_folds}...\")\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        model = EfficientNetFPN(out_channels=1, pretrained=True).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"fold_{fold}_checkpoint.pth\")\n",
    "        start_epoch, start_batch = 0, 0\n",
    "\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            start_batch = checkpoint['batch']\n",
    "            print(f\"Resuming fold {fold} from epoch {start_epoch + 1}, batch {start_batch + 1}\")\n",
    "        else:\n",
    "            print(f\"Starting fold {fold} from scratch.\")\n",
    "\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", initial=start_batch, total=len(train_loader))\n",
    "            for batch_idx, (images, masks) in enumerate(pbar, start=start_batch):\n",
    "                if batch_idx < start_batch:\n",
    "                    continue\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = bce_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'batch': batch_idx,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, checkpoint_path)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "            start_batch = 0\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    outputs = model(images)\n",
    "                    val_loss += bce_loss(outputs, masks).item()\n",
    "            print(f\"Validation Loss after Epoch {epoch + 1}: {val_loss / len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this below piece of code for training....... after running the above cells once!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n",
      "Starting fold 1 from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/62088 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "image_dir = \"E:/kits23/split_dataset/train/images/\"\n",
    "mask_dir = \"E:/kits23/split_dataset/train/masks/\"\n",
    "train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
