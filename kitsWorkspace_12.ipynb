{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(BCEFocalLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Flatten the inputs and targets\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # Compute BCE loss\n",
    "        bce_loss = self.bce_loss(inputs, targets)\n",
    "\n",
    "        # Compute Focal Loss modulation factor\n",
    "        pt = torch.exp(-bce_loss)  # Probability of the true class\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Example usage:\n",
    "# combined_loss = BCEFocalLoss(alpha=0.25, gamma=2)\n",
    "# loss = combined_loss(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folder: 00000\n",
      "Image shape: (1, 512, 512)\n",
      "Mask shape: (1, 512, 512)\n",
      "--------------------------------------------------\n",
      "Case Folder: 00001\n",
      "Image shape: (1, 512, 512)\n",
      "Mask shape: (1, 512, 512)\n",
      "--------------------------------------------------\n",
      "Case Folder: 00002\n",
      "Image shape: (1, 512, 512)\n",
      "Mask shape: (1, 512, 512)\n",
      "--------------------------------------------------\n",
      "Case Folder: 00003\n",
      "Image shape: (1, 512, 512)\n",
      "Mask shape: (1, 512, 512)\n",
      "--------------------------------------------------\n",
      "Case Folder: 00004\n",
      "Image shape: (1, 512, 512)\n",
      "Mask shape: (1, 512, 512)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# Define the paths\n",
    "images_path = \"E:/kits23/2d_slices/images/\"\n",
    "masks_path = \"E:/kits23/2d_slices/masks/\"\n",
    "\n",
    "# Function to check dimensions of images and masks\n",
    "def check_image_mask_dimensions(images_path, masks_path):\n",
    "    image_case_folders = sorted(os.listdir(images_path))  # Sort image case folders\n",
    "    mask_case_folders = sorted(os.listdir(masks_path))    # Sort mask case folders\n",
    "\n",
    "    # Loop through a few cases to check dimensions\n",
    "    for case_folder in image_case_folders[:5]:  # Check first 5 cases, adjust as needed\n",
    "        image_case_path = os.path.join(images_path, case_folder)\n",
    "        mask_case_path = os.path.join(masks_path, case_folder)\n",
    "\n",
    "        # Get image and mask files inside the case folder (they should be .nii.gz files)\n",
    "        image_files = sorted([f for f in os.listdir(image_case_path) if f.endswith('.nii.gz')])\n",
    "        mask_files = sorted([f for f in os.listdir(mask_case_path) if f.endswith('.nii.gz')])\n",
    "\n",
    "        if not image_files or not mask_files:\n",
    "            print(f\"Warning: No valid .nii.gz files found in {image_case_path} or {mask_case_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load image and mask (assuming 1:1 correspondence between slices)\n",
    "        image = nib.load(os.path.join(image_case_path, image_files[0])).get_fdata()\n",
    "        mask = nib.load(os.path.join(mask_case_path, mask_files[0])).get_fdata()\n",
    "\n",
    "        # Print the dimensions\n",
    "        print(f\"Case Folder: {case_folder}\")\n",
    "        print(f\"Image shape: {image.shape}\")\n",
    "        print(f\"Mask shape: {mask.shape}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Check dimensions of images and masks\n",
    "check_image_mask_dimensions(images_path, masks_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folder: 00000\n",
      "Image shape: (512, 512)\n",
      "Mask shape: (512, 512)\n",
      "--------------------------------------------------\n",
      "Case Folder: 00001\n",
      "Image shape: (512, 512)\n",
      "Mask shape: (512, 512)\n",
      "--------------------------------------------------\n",
      "Case Folder: 00002\n",
      "Image shape: (512, 512)\n",
      "Mask shape: (512, 512)\n",
      "--------------------------------------------------\n",
      "Case Folder: 00003\n",
      "Image shape: (512, 512)\n",
      "Mask shape: (512, 512)\n",
      "--------------------------------------------------\n",
      "Case Folder: 00004\n",
      "Image shape: (512, 512)\n",
      "Mask shape: (512, 512)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# Define the paths\n",
    "images_path = \"E:/kits23/2d_slices/images/\"\n",
    "masks_path = \"E:/kits23/2d_slices/masks/\"\n",
    "\n",
    "# Function to check dimensions of images and masks\n",
    "def check_image_mask_dimensions(images_path, masks_path):\n",
    "    image_case_folders = sorted(os.listdir(images_path))  # Sort image case folders\n",
    "    mask_case_folders = sorted(os.listdir(masks_path))    # Sort mask case folders\n",
    "\n",
    "    # Loop through a few cases to check dimensions\n",
    "    for case_folder in image_case_folders[:5]:  # Check first 5 cases, adjust as needed\n",
    "        image_case_path = os.path.join(images_path, case_folder)\n",
    "        mask_case_path = os.path.join(masks_path, case_folder)\n",
    "\n",
    "        # Get image and mask files inside the case folder (they should be .nii.gz files)\n",
    "        image_files = sorted([f for f in os.listdir(image_case_path) if f.endswith('.nii.gz')])\n",
    "        mask_files = sorted([f for f in os.listdir(mask_case_path) if f.endswith('.nii.gz')])\n",
    "\n",
    "        if not image_files or not mask_files:\n",
    "            print(f\"Warning: No valid .nii.gz files found in {image_case_path} or {mask_case_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load image and mask (assuming 1:1 correspondence between slices)\n",
    "        image = nib.load(os.path.join(image_case_path, image_files[0])).get_fdata()\n",
    "        mask = nib.load(os.path.join(mask_case_path, mask_files[0])).get_fdata()\n",
    "\n",
    "        # Extract 2D slice (indexing the first dimension)\n",
    "        image_slice = image[0, :, :]  # Assuming first dimension is of size 1\n",
    "        mask_slice = mask[0, :, :]    # Assuming first dimension is of size 1\n",
    "\n",
    "        # Print the dimensions\n",
    "        print(f\"Case Folder: {case_folder}\")\n",
    "        print(f\"Image shape: {image_slice.shape}\")\n",
    "        print(f\"Mask shape: {mask_slice.shape}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Check dimensions of images and masks\n",
    "check_image_mask_dimensions(images_path, masks_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Training cases: ['00129', '00041', '00045', '00230', '00094', '00198', '00484', '00555', '00004', '00175', '00437', '00458', '00487', '00188', '00532', '00209', '00007', '00242', '00021', '00050', '00096', '00196', '00288', '00293', '00059', '00284', '00132', '00144', '00552', '00505', '00184', '00267', '00213', '00164', '00412', '00528', '00170', '00139', '00089', '00422', '00266', '00526', '00424', '00074', '00037', '00286', '00088', '00240', '00297', '00127', '00414', '00160', '00092', '00100', '00558', '00109', '00404', '00182', '00469', '00120', '00093', '00179', '00026', '00568', '00413', '00199', '00095', '00155', '00419', '00223', '00253', '00241', '00444', '00085', '00415', '00483', '00481', '00038', '00227', '00069', '00106', '00439', '00143', '00565', '00531', '00031', '00177', '00008', '00261', '00461', '00141', '00580', '00211', '00068', '00448', '00072', '00251', '00002', '00442', '00207', '00076', '00244', '00407', '00178', '00268', '00560', '00538', '00066', '00163', '00133', '00496', '00153', '00263', '00482', '00145', '00566', '00190', '00151', '00017', '00537', '00291', '00280', '00577', '00294', '00149', '00491', '00492', '00417', '00534', '00523', '00508', '00014', '00055', '00075', '00208', '00039', '00187', '00503', '00212', '00546', '00510', '00067', '00099', '00554', '00498', '00278', '00478', '00246', '00292', '00247', '00233', '00042', '00475', '00548', '00509', '00474', '00217', '00584', '00113', '00019', '00210', '00118', '00249', '00441', '00453', '00582', '00468', '00518', '00524', '00486', '00086', '00418', '00103', '00570', '00025', '00400', '00167', '00564', '00500', '00221', '00506', '00105', '00277', '00090', '00541', '00269', '00048', '00104', '00206', '00238', '00200', '00062', '00121', '00147', '00146', '00225', '00493', '00296', '00467', '00480', '00410', '00124', '00171', '00455', '00060', '00131', '00018', '00521', '00220', '00471', '00034', '00262', '00030', '00540', '00550', '00445', '00010', '00173', '00115', '00454', '00061', '00231', '00264', '00447', '00159', '00403', '00463', '00462', '00428', '00456', '00084', '00281', '00243', '00065', '00064', '00272', '00529', '00248', '00043', '00465', '00123', '00029', '00122', '00157', '00578', '00420', '00250', '00165', '00000', '00271', '00276', '00191', '00511', '00562', '00489', '00152', '00256', '00001', '00222', '00520', '00587', '00544', '00525', '00058', '00005', '00283', '00128', '00270', '00434', '00195', '00197', '00032', '00405', '00547', '00519', '00056', '00046', '00252', '00260', '00070', '00476', '00517', '00204', '00298', '00219', '00299', '00134', '00275', '00563', '00126', '00581', '00530', '00073', '00234', '00429', '00255', '00435', '00561', '00290', '00108', '00033', '00137', '00205', '00161', '00571', '00117', '00028', '00166', '00450', '00285', '00588', '00138', '00236', '00499', '00583', '00527', '00273', '00087', '00501', '00411', '00431', '00449', '00136', '00443', '00107', '00083', '00186', '00425', '00232', '00536', '00051', '00567', '00148', '00495', '00116', '00438', '00023', '00035', '00460', '00098', '00295', '00185', '00416', '00421', '00282', '00193', '00274', '00176', '00533', '00049', '00194', '00569', '00579', '00172', '00490', '00110', '00553', '00174', '00572', '00457', '00081', '00512', '00488', '00003', '00514', '00142', '00401', '00229', '00112', '00214', '00575', '00459', '00432', '00101', '00287', '00013', '00408', '00258', '00119', '00047', '00015', '00016', '00402', '00279', '00556', '00585', '00071', '00479', '00012', '00057', '00427']\n",
      "  Testing cases: ['00485', '00154', '00423', '00156', '00254', '00192', '00203', '00497', '00218', '00053', '00158', '00557', '00228', '00201', '00180', '00549', '00426', '00011', '00006', '00265', '00237', '00436', '00289', '00077', '00515', '00573', '00516', '00406', '00574', '00464', '00542', '00257', '00215', '00020', '00130', '00162', '00169', '00097', '00245', '00586', '00226', '00535', '00027', '00539', '00168', '00440', '00472', '00433', '00224', '00430', '00102', '00507', '00009', '00082', '00054', '00259', '00091', '00451', '00502', '00080', '00494', '00239', '00551', '00078', '00024', '00202', '00470', '00576', '00452', '00504', '00036', '00559', '00181', '00189', '00543', '00522', '00150', '00040', '00063', '00235', '00473', '00022', '00513', '00135', '00409', '00183', '00079', '00545', '00466', '00111', '00216', '00044', '00446', '00052', '00477', '00114', '00125', '00140']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_file, mask_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(image_files, mask_files):\n\u001b[0;32m     61\u001b[0m     image \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_case_path, image_file))\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[1;32m---> 62\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_case_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[0;32m     64\u001b[0m     train_images\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[0;32m     65\u001b[0m     train_masks\u001b[38;5;241m.\u001b[39mappend(mask)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nibabel\\loadsave.py:109\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m sniff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_klass \u001b[38;5;129;01min\u001b[39;00m all_image_classes:\n\u001b[1;32m--> 109\u001b[0m     is_valid, sniff \u001b[38;5;241m=\u001b[39m \u001b[43mimage_klass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_maybe_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msniff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid:\n\u001b[0;32m    111\u001b[0m         img \u001b[38;5;241m=\u001b[39m image_klass\u001b[38;5;241m.\u001b[39mfrom_filename(filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nibabel\\filebasedimages.py:477\u001b[0m, in \u001b[0;36mFileBasedImage.path_maybe_image\u001b[1;34m(klass, filename, sniff, sniff_max)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sniff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sniff[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m klass\u001b[38;5;241m.\u001b[39m_meta_sniff_len:\n\u001b[0;32m    476\u001b[0m     sniff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m sniff \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sniff_meta_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta_sniff_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msniff_max\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msniff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sniff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sniff[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m klass\u001b[38;5;241m.\u001b[39m_meta_sniff_len:\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, sniff\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nibabel\\filebasedimages.py:422\u001b[0m, in \u001b[0;36mFileBasedImage._sniff_meta_for\u001b[1;34m(klass, filename, sniff_nbytes, sniff)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Attempt to sniff from metadata location\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mImageOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_fname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    423\u001b[0m         binaryblock \u001b[38;5;241m=\u001b[39m fobj\u001b[38;5;241m.\u001b[39mread(sniff_nbytes)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m COMPRESSION_ERRORS \u001b[38;5;241m+\u001b[39m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nibabel\\openers.py:181\u001b[0m, in \u001b[0;36mOpener.__init__\u001b[1;34m(self, fileish, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Clear keep_open hint if it is not relevant for the file type\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep_open\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobj \u001b[38;5;241m=\u001b[39m opener(fileish, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m fileish\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mme_opened \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nibabel\\openers.py:89\u001b[0m, in \u001b[0;36m_gzip_open\u001b[1;34m(filename, mode, compresslevel, mtime, keep_open)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gzip_open\u001b[39m(\n\u001b[0;32m     82\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     83\u001b[0m     mode: Mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     keep_open: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     87\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m HAVE_INDEXED_GZIP \u001b[38;5;129;01mor\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 89\u001b[0m         gzip_file \u001b[38;5;241m=\u001b[39m \u001b[43mDeterministicGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# use indexed_gzip if possible for faster read access.  If keep_open ==\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# True, we tell IndexedGzipFile to keep the file handle open. Otherwise\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# the IndexedGzipFile will close/open the file on each read.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m         gzip_file \u001b[38;5;241m=\u001b[39m IndexedGzipFile(filename, drop_handles\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m keep_open)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nibabel\\openers.py:71\u001b[0m, in \u001b[0;36mDeterministicGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMust define either fileobj or filename\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Cast because GzipFile.myfileobj has type io.FileIO while open returns ty.IO\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m ty\u001b[38;5;241m.\u001b[39mcast(io\u001b[38;5;241m.\u001b[39mFileIO, \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodestr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     73\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     74\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmodestr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     mtime\u001b[38;5;241m=\u001b[39mmtime,\n\u001b[0;32m     78\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define paths\n",
    "images_path = \"E:/kits23/2d_slices/images/\"\n",
    "masks_path = \"E:/kits23/2d_slices/masks/\"\n",
    "\n",
    "# Get all case folders\n",
    "image_case_folders = sorted(os.listdir(images_path))  # List of image case folders\n",
    "mask_case_folders = sorted(os.listdir(masks_path))    # List of mask case folders\n",
    "\n",
    "# Ensure the same number of case folders in both images and masks\n",
    "assert len(image_case_folders) == len(mask_case_folders), \"Mismatch in number of case folders.\"\n",
    "\n",
    "# Shuffle the case folders\n",
    "random.seed(42)  # For reproducibility\n",
    "random.shuffle(image_case_folders)\n",
    "\n",
    "# Create KFold object for 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Function to pad images and masks to the same number of slices\n",
    "def pad_to_max_slices(image, mask, max_slices):\n",
    "    # Pad image and mask to the max_slices dimension\n",
    "    pad_size = max_slices - image.shape[0]\n",
    "    if pad_size > 0:\n",
    "        image = np.pad(image, ((0, pad_size), (0, 0), (0, 0)), mode='constant')\n",
    "        mask = np.pad(mask, ((0, pad_size), (0, 0), (0, 0)), mode='constant')\n",
    "    return image, mask\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "fold = 1\n",
    "for train_idx, test_idx in kf.split(image_case_folders):\n",
    "    train_cases = [image_case_folders[i] for i in train_idx]\n",
    "    test_cases = [image_case_folders[i] for i in test_idx]\n",
    "\n",
    "    # Print out the train and test cases for this fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Training cases: {train_cases}\")\n",
    "    print(f\"  Testing cases: {test_cases}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Prepare the data for this fold\n",
    "    train_images = []\n",
    "    train_masks = []\n",
    "    test_images = []\n",
    "    test_masks = []\n",
    "\n",
    "    # Collect images and masks for training\n",
    "    for case_folder in train_cases:\n",
    "        image_case_path = os.path.join(images_path, case_folder)\n",
    "        mask_case_path = os.path.join(masks_path, case_folder)\n",
    "\n",
    "        image_files = sorted([f for f in os.listdir(image_case_path) if f.endswith('.nii.gz')])\n",
    "        mask_files = sorted([f for f in os.listdir(mask_case_path) if f.endswith('.nii.gz')])\n",
    "\n",
    "        for image_file, mask_file in zip(image_files, mask_files):\n",
    "            image = nib.load(os.path.join(image_case_path, image_file)).get_fdata()\n",
    "            mask = nib.load(os.path.join(mask_case_path, mask_file)).get_fdata()\n",
    "\n",
    "            train_images.append(image)\n",
    "            train_masks.append(mask)\n",
    "\n",
    "    # Collect images and masks for testing\n",
    "    for case_folder in test_cases:\n",
    "        image_case_path = os.path.join(images_path, case_folder)\n",
    "        mask_case_path = os.path.join(masks_path, case_folder)\n",
    "\n",
    "        image_files = sorted([f for f in os.listdir(image_case_path) if f.endswith('.nii.gz')])\n",
    "        mask_files = sorted([f for f in os.listdir(mask_case_path) if f.endswith('.nii.gz')])\n",
    "\n",
    "        for image_file, mask_file in zip(image_files, mask_files):\n",
    "            image = nib.load(os.path.join(image_case_path, image_file)).get_fdata()\n",
    "            mask = nib.load(os.path.join(mask_case_path, mask_file)).get_fdata()\n",
    "\n",
    "            test_images.append(image)\n",
    "            test_masks.append(mask)\n",
    "\n",
    "    # Determine the maximum number of slices in the training set\n",
    "    max_slices = max([img.shape[0] for img in train_images])\n",
    "\n",
    "    # Pad images and masks for training and testing\n",
    "    padded_train_images = []\n",
    "    padded_train_masks = []\n",
    "    for img, msk in zip(train_images, train_masks):\n",
    "        padded_img, padded_msk = pad_to_max_slices(img, msk, max_slices)\n",
    "        padded_train_images.append(padded_img)\n",
    "        padded_train_masks.append(padded_msk)\n",
    "\n",
    "    padded_test_images = []\n",
    "    padded_test_masks = []\n",
    "    for img, msk in zip(test_images, test_masks):\n",
    "        padded_img, padded_msk = pad_to_max_slices(img, msk, max_slices)\n",
    "        padded_test_images.append(padded_img)\n",
    "        padded_test_masks.append(padded_msk)\n",
    "\n",
    "    # Here you can now train and evaluate your model using padded_train_images and padded_train_masks\n",
    "    # as the training data, and padded_test_images and padded_test_masks as the test data.\n",
    "\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Training cases: ['00129', '00041', '00045', '00230', '00094', '00198', '00484', '00555', '00004', '00175', '00437', '00458', '00487', '00188', '00532', '00209', '00007', '00242', '00021', '00050', '00096', '00196', '00288', '00293', '00059', '00284', '00132', '00144', '00552', '00505', '00184', '00267', '00213', '00164', '00412', '00528', '00170', '00139', '00089', '00422', '00266', '00526', '00424', '00074', '00037', '00286', '00088', '00240', '00297', '00127', '00414', '00160', '00092', '00100', '00558', '00109', '00404', '00182', '00469', '00120', '00093', '00179', '00026', '00568', '00413', '00199', '00095', '00155', '00419', '00223', '00253', '00241', '00444', '00085', '00415', '00483', '00481', '00038', '00227', '00069', '00106', '00439', '00143', '00565', '00531', '00031', '00177', '00008', '00261', '00461', '00141', '00580', '00211', '00068', '00448', '00072', '00251', '00002', '00442', '00207', '00076', '00244', '00407', '00178', '00268', '00560', '00538', '00066', '00163', '00133', '00496', '00153', '00263', '00482', '00145', '00566', '00190', '00151', '00017', '00537', '00291', '00280', '00577', '00294', '00149', '00491', '00492', '00417', '00534', '00523', '00508', '00014', '00055', '00075', '00208', '00039', '00187', '00503', '00212', '00546', '00510', '00067', '00099', '00554', '00498', '00278', '00478', '00246', '00292', '00247', '00233', '00042', '00475', '00548', '00509', '00474', '00217', '00584', '00113', '00019', '00210', '00118', '00249', '00441', '00453', '00582', '00468', '00518', '00524', '00486', '00086', '00418', '00103', '00570', '00025', '00400', '00167', '00564', '00500', '00221', '00506', '00105', '00277', '00090', '00541', '00269', '00048', '00104', '00206', '00238', '00200', '00062', '00121', '00147', '00146', '00225', '00493', '00296', '00467', '00480', '00410', '00124', '00171', '00455', '00060', '00131', '00018', '00521', '00220', '00471', '00034', '00262', '00030', '00540', '00550', '00445', '00010', '00173', '00115', '00454', '00061', '00231', '00264', '00447', '00159', '00403', '00463', '00462', '00428', '00456', '00084', '00281', '00243', '00065', '00064', '00272', '00529', '00248', '00043', '00465', '00123', '00029', '00122', '00157', '00578', '00420', '00250', '00165', '00000', '00271', '00276', '00191', '00511', '00562', '00489', '00152', '00256', '00001', '00222', '00520', '00587', '00544', '00525', '00058', '00005', '00283', '00128', '00270', '00434', '00195', '00197', '00032', '00405', '00547', '00519', '00056', '00046', '00252', '00260', '00070', '00476', '00517', '00204', '00298', '00219', '00299', '00134', '00275', '00563', '00126', '00581', '00530', '00073', '00234', '00429', '00255', '00435', '00561', '00290', '00108', '00033', '00137', '00205', '00161', '00571', '00117', '00028', '00166', '00450', '00285', '00588', '00138', '00236', '00499', '00583', '00527', '00273', '00087', '00501', '00411', '00431', '00449', '00136', '00443', '00107', '00083', '00186', '00425', '00232', '00536', '00051', '00567', '00148', '00495', '00116', '00438', '00023', '00035', '00460', '00098', '00295', '00185', '00416', '00421', '00282', '00193', '00274', '00176', '00533', '00049', '00194', '00569', '00579', '00172', '00490', '00110', '00553', '00174', '00572', '00457', '00081', '00512', '00488', '00003', '00514', '00142', '00401', '00229', '00112', '00214', '00575', '00459', '00432', '00101', '00287', '00013', '00408', '00258', '00119', '00047', '00015', '00016', '00402', '00279', '00556', '00585', '00071', '00479', '00012', '00057', '00427']\n",
      "  Testing cases: ['00485', '00154', '00423', '00156', '00254', '00192', '00203', '00497', '00218', '00053', '00158', '00557', '00228', '00201', '00180', '00549', '00426', '00011', '00006', '00265', '00237', '00436', '00289', '00077', '00515', '00573', '00516', '00406', '00574', '00464', '00542', '00257', '00215', '00020', '00130', '00162', '00169', '00097', '00245', '00586', '00226', '00535', '00027', '00539', '00168', '00440', '00472', '00433', '00224', '00430', '00102', '00507', '00009', '00082', '00054', '00259', '00091', '00451', '00502', '00080', '00494', '00239', '00551', '00078', '00024', '00202', '00470', '00576', '00452', '00504', '00036', '00559', '00181', '00189', '00543', '00522', '00150', '00040', '00063', '00235', '00473', '00022', '00513', '00135', '00409', '00183', '00079', '00545', '00466', '00111', '00216', '00044', '00446', '00052', '00477', '00114', '00125', '00140']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define paths\n",
    "images_path = \"E:/kits23/2d_slices/images/\"\n",
    "masks_path = \"E:/kits23/2d_slices/masks/\"\n",
    "\n",
    "# Define output paths for saving padded images and masks\n",
    "output_images_path = \"E:/kits23/padded_images/\"\n",
    "output_masks_path = \"E:/kits23/padded_masks/\"\n",
    "\n",
    "# Get all case folders\n",
    "image_case_folders = sorted(os.listdir(images_path))  # List of image case folders\n",
    "mask_case_folders = sorted(os.listdir(masks_path))    # List of mask case folders\n",
    "\n",
    "# Ensure the same number of case folders in both images and masks\n",
    "assert len(image_case_folders) == len(mask_case_folders), \"Mismatch in number of case folders.\"\n",
    "\n",
    "# Shuffle the case folders\n",
    "random.seed(42)  # For reproducibility\n",
    "random.shuffle(image_case_folders)\n",
    "\n",
    "# Create KFold object for 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Function to pad images and masks to the same number of slices\n",
    "def pad_to_max_slices(image, mask, max_slices):\n",
    "    # Pad image and mask to the max_slices dimension\n",
    "    pad_size = max_slices - image.shape[0]\n",
    "    if pad_size > 0:\n",
    "        image = np.pad(image, ((0, pad_size), (0, 0), (0, 0)), mode='constant')\n",
    "        mask = np.pad(mask, ((0, pad_size), (0, 0), (0, 0)), mode='constant')\n",
    "    return image, mask\n",
    "\n",
    "# Function to save padded images and masks\n",
    "def save_padded_data(images, masks, output_images_path, output_masks_path, case_folder, fold_type):\n",
    "    os.makedirs(output_images_path, exist_ok=True)\n",
    "    os.makedirs(output_masks_path, exist_ok=True)\n",
    "\n",
    "    for idx, (image, mask) in enumerate(zip(images, masks)):\n",
    "        # Save each padded image and mask\n",
    "        image_filename = f\"{case_folder}_{fold_type}_slice_{idx}.nii.gz\"\n",
    "        mask_filename = f\"{case_folder}_{fold_type}_slice_{idx}_mask.nii.gz\"\n",
    "\n",
    "        # Create NIfTI image and mask objects\n",
    "        img_nifti = nib.Nifti1Image(image, np.eye(4))  # Assuming no affine transformation\n",
    "        mask_nifti = nib.Nifti1Image(mask, np.eye(4))\n",
    "\n",
    "        # Save the NIfTI files\n",
    "        nib.save(img_nifti, os.path.join(output_images_path, image_filename))\n",
    "        nib.save(mask_nifti, os.path.join(output_masks_path, mask_filename))\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "fold = 1\n",
    "for train_idx, test_idx in kf.split(image_case_folders):\n",
    "    train_cases = [image_case_folders[i] for i in train_idx]\n",
    "    test_cases = [image_case_folders[i] for i in test_idx]\n",
    "\n",
    "    # Print out the train and test cases for this fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Training cases: {train_cases}\")\n",
    "    print(f\"  Testing cases: {test_cases}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Prepare the data for this fold\n",
    "    train_images = []\n",
    "    train_masks = []\n",
    "    test_images = []\n",
    "    test_masks = []\n",
    "\n",
    "    # Collect images and masks for training\n",
    "    for case_folder in train_cases:\n",
    "        image_case_path = os.path.join(images_path, case_folder)\n",
    "        mask_case_path = os.path.join(masks_path, case_folder)\n",
    "\n",
    "        image_files = sorted([f for f in os.listdir(image_case_path) if f.endswith('.nii.gz')])\n",
    "        mask_files = sorted([f for f in os.listdir(mask_case_path) if f.endswith('.nii.gz')])\n",
    "\n",
    "        for image_file, mask_file in zip(image_files, mask_files):\n",
    "            image = nib.load(os.path.join(image_case_path, image_file)).get_fdata()\n",
    "            mask = nib.load(os.path.join(mask_case_path, mask_file)).get_fdata()\n",
    "\n",
    "            train_images.append(image)\n",
    "            train_masks.append(mask)\n",
    "\n",
    "    # Collect images and masks for testing\n",
    "    for case_folder in test_cases:\n",
    "        image_case_path = os.path.join(images_path, case_folder)\n",
    "        mask_case_path = os.path.join(masks_path, case_folder)\n",
    "\n",
    "        image_files = sorted([f for f in os.listdir(image_case_path) if f.endswith('.nii.gz')])\n",
    "        mask_files = sorted([f for f in os.listdir(mask_case_path) if f.endswith('.nii.gz')])\n",
    "\n",
    "        for image_file, mask_file in zip(image_files, mask_files):\n",
    "            image = nib.load(os.path.join(image_case_path, image_file)).get_fdata()\n",
    "            mask = nib.load(os.path.join(mask_case_path, mask_file)).get_fdata()\n",
    "\n",
    "            test_images.append(image)\n",
    "            test_masks.append(mask)\n",
    "\n",
    "    # Determine the maximum number of slices in the training set\n",
    "    max_slices = max([img.shape[0] for img in train_images])\n",
    "\n",
    "    # Pad images and masks for training and testing\n",
    "    padded_train_images = []\n",
    "    padded_train_masks = []\n",
    "    for img, msk in zip(train_images, train_masks):\n",
    "        padded_img, padded_msk = pad_to_max_slices(img, msk, max_slices)\n",
    "        padded_train_images.append(padded_img)\n",
    "        padded_train_masks.append(padded_msk)\n",
    "\n",
    "    padded_test_images = []\n",
    "    padded_test_masks = []\n",
    "    for img, msk in zip(test_images, test_masks):\n",
    "        padded_img, padded_msk = pad_to_max_slices(img, msk, max_slices)\n",
    "        padded_test_images.append(padded_img)\n",
    "        padded_test_masks.append(padded_msk)\n",
    "\n",
    "    # Save padded images and masks for this fold\n",
    "    save_padded_data(padded_train_images, padded_train_masks, output_images_path, output_masks_path, f\"train_fold_{fold}\")\n",
    "    save_padded_data(padded_test_images, padded_test_masks, output_images_path, output_masks_path, f\"test_fold_{fold}\")\n",
    "\n",
    "    # You can now train and evaluate your model using padded_train_images and padded_train_masks\n",
    "    # for training and padded_test_images and padded_test_masks for evaluation.\n",
    "\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case slice - Image file: slice_000.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_000.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_001.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_001.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_002.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_002.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_003.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_003.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_004.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_004.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_005.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_005.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_006.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_006.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_007.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_007.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_008.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_008.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_009.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_009.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_010.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_010.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_011.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_011.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_012.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_012.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_013.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_013.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_014.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_014.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_015.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_015.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_016.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_016.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_017.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_017.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_018.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_018.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_019.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_019.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_020.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_020.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_021.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_021.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_022.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_022.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_023.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_023.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_024.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_024.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_025.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_025.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_026.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_026.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_027.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_027.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_028.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_028.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_029.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_029.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_030.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_030.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_031.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_031.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_032.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_032.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_033.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_033.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_034.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_034.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_035.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_035.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_036.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_036.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_037.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_037.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_038.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_038.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_039.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_039.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_040.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_040.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_041.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_041.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_042.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_042.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_043.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_043.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_044.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_044.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_045.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_045.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_046.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_046.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_047.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_047.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_048.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_048.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_049.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_049.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_050.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_050.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_051.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_051.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_052.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_052.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_053.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_053.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_054.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_054.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_055.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_055.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_056.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_056.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_057.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_057.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_058.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_058.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_059.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_059.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_060.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_060.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_061.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_061.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_062.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_062.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_063.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_063.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_064.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_064.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_065.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_065.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_066.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_066.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_067.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_067.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_068.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_068.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_069.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_069.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_070.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_070.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_071.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_071.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_072.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_072.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_073.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_073.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_074.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_074.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_075.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_075.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_076.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_076.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_077.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_077.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_078.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_078.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_079.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_079.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_080.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_080.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_081.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_081.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_082.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_082.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_083.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_083.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_084.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_084.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_085.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_085.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_086.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_086.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_087.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_087.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_088.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_088.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_089.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_089.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_090.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_090.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_091.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_091.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_092.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_092.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_093.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_093.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_094.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_094.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_095.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_095.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_096.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_096.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_097.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_097.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_098.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_098.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_099.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_099.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_100.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_100.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_101.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_101.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_102.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_102.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_103.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_103.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_104.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_104.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_105.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_105.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_106.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_106.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_107.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_107.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_108.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_108.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_109.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_109.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_110.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_110.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_111.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_111.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_112.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_112.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_113.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_113.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_114.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_114.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_115.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_115.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_116.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_116.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_117.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_117.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_118.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_118.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_119.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_119.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_120.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_120.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_121.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_121.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_122.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_122.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_123.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_123.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_124.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_124.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_125.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_125.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_126.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_126.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_127.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_127.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_128.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_128.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_129.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_129.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_130.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_130.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_131.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_131.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_132.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_132.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_133.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_133.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_134.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_134.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_135.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_135.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_136.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_136.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_137.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_137.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_138.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_138.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_139.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_139.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_140.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_140.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_141.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_141.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_142.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_142.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_143.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_143.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_144.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_144.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_145.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_145.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_146.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_146.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_147.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_147.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_148.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_148.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_149.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_149.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_150.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_150.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_151.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_151.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_152.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_152.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_153.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_153.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_154.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_154.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_155.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_155.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_156.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_156.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_157.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_157.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_158.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_158.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_159.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_159.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_160.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_160.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_161.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_161.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_162.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_162.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_163.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_163.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_164.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_164.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_165.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_165.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_166.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_166.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_167.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_167.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_168.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_168.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_169.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_169.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_170.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_170.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_171.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_171.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_172.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_172.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_173.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_173.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_174.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_174.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_175.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_175.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_176.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_176.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_177.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_177.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_178.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_178.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_179.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_179.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_180.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_180.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_181.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_181.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_182.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_182.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_183.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_183.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_184.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_184.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_185.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_185.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_186.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_186.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_187.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_187.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_188.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_188.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_189.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_189.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_190.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_190.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_191.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_191.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_192.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_192.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_193.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_193.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_194.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_194.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_195.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_195.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_196.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_196.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_197.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_197.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_198.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_198.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_199.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_199.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_200.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_200.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_201.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_201.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_202.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_202.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_203.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_203.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_204.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_204.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_205.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_205.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_206.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_206.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_207.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_207.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_208.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_208.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_209.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_209.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_210.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_210.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_211.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_211.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_212.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_212.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_213.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_213.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_214.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_214.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_215.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_215.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_216.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_216.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_217.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_217.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_218.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_218.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_219.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_219.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_220.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_220.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_221.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_221.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_222.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_222.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_223.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_223.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_224.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_224.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_225.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_225.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_226.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_226.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_227.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_227.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_228.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_228.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_229.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_229.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_230.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_230.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_231.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_231.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_232.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_232.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_233.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_233.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_234.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_234.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_235.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_235.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_236.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_236.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_237.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_237.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_238.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_238.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_239.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_239.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_240.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_240.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_241.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_241.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_242.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_242.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_243.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_243.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_244.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_244.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_245.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_245.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_246.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_246.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_247.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_247.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_248.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_248.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_249.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_249.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_250.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_250.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_251.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_251.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_252.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_252.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_253.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_253.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_254.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_254.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_255.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_255.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_256.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_256.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_257.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_257.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_258.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_258.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_259.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_259.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_260.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_260.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_261.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_261.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_262.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_262.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_263.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_263.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_264.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_264.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_265.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_265.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_266.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_266.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_267.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_267.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_268.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_268.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_269.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_269.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_270.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_270.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_271.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_271.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_272.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_272.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_273.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_273.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_274.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_274.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_275.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_275.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_276.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_276.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_277.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_277.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_278.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_278.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_279.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_279.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_280.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_280.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_281.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_281.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_282.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_282.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_283.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_283.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_284.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_284.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_285.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_285.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_286.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_286.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_287.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_287.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_288.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_288.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_289.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_289.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_290.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_290.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_291.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_291.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_292.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_292.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_293.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_293.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_294.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_294.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_295.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_295.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_296.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_296.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_297.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_297.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_298.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_298.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_299.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_299.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_300.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_300.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_301.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_301.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_302.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_302.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_303.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_303.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_304.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_304.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Image file: slice_305.nii.gz - Shape: (1, 512, 512)\n",
      "Case slice - Mask file: slice_305.nii.gz - Shape: (1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# Define the paths to the images and masks folders\n",
    "image_folder = \"E:/kits23/2d_slices/images/00000\"\n",
    "mask_folder = \"E:/kits23/2d_slices/masks/00000\"\n",
    "\n",
    "# Get a list of all the files (slices) in the image and mask folders\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.nii.gz')]\n",
    "mask_files = [f for f in os.listdir(mask_folder) if f.endswith('.nii.gz')]\n",
    "\n",
    "# Check if the number of image files matches the number of mask files\n",
    "if len(image_files) != len(mask_files):\n",
    "    print(f\"Warning: Number of images ({len(image_files)}) does not match number of masks ({len(mask_files)})\")\n",
    "\n",
    "# Loop through the image files and corresponding mask files\n",
    "for image_file, mask_file in zip(image_files, mask_files):\n",
    "    # Load the image and mask using nibabel\n",
    "    image = nib.load(os.path.join(image_folder, image_file)).get_fdata()\n",
    "    mask = nib.load(os.path.join(mask_folder, mask_file)).get_fdata()\n",
    "    \n",
    "    # Get the shape (dimensions) of the image and mask\n",
    "    image_shape = image.shape\n",
    "    mask_shape = mask.shape\n",
    "    \n",
    "    # Print the case number, image file name, and its dimensions\n",
    "    case_number = os.path.basename(image_file).split('_')[0]  # Extract case number from the file name\n",
    "    print(f\"Case {case_number} - Image file: {image_file} - Shape: {image_shape}\")\n",
    "    print(f\"Case {case_number} - Mask file: {mask_file} - Shape: {mask_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([2, 1, 512, 512])\n",
      "Loss:  0.7230997681617737\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.optim import Adam\n",
    "\n",
    "# EfficientNet-B5 Encoder (from torchvision)\n",
    "class EfficientNetB5Encoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EfficientNetB5Encoder, self).__init__()\n",
    "        # Load the pre-trained EfficientNet-B5 model from torchvision\n",
    "        self.encoder = models.efficientnet_b5(pretrained=pretrained)\n",
    "        \n",
    "        # Remove the classification head (fully connected layers) to retain features\n",
    "        self.encoder = nn.Sequential(*list(self.encoder.children())[:-1])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from the encoder\n",
    "        features = self.encoder(x)\n",
    "        return features\n",
    "\n",
    "# FPN Decoder\n",
    "class FPNDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FPNDecoder, self).__init__()\n",
    "        # FPN typically uses several layers to combine features from different scales\n",
    "        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Instead of fixed upsampling, use adaptive upsampling\n",
    "        self.upsample = nn.Upsample(size=(512, 512), mode='bilinear', align_corners=True)  # Adaptive resizing to (512, 512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Decode and combine features from multiple scales\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Upsample the output to match the input size (512x512)\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "\n",
    "# Final model combining EfficientNet-B5 and FPN\n",
    "class EfficientNetFPN(nn.Module):\n",
    "    def __init__(self, out_channels=1, pretrained=True):\n",
    "        super(EfficientNetFPN, self).__init__()\n",
    "        # Encoder: EfficientNetB5\n",
    "        self.encoder = EfficientNetB5Encoder(pretrained=pretrained)\n",
    "        \n",
    "        # Decoder: FPN\n",
    "        self.decoder = FPNDecoder(in_channels=2048, out_channels=out_channels)  # EfficientNet-B5 has 2048 channels in the final layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through encoder and decoder\n",
    "        features = self.encoder(x)\n",
    "        out = self.decoder(features)\n",
    "        return out\n",
    "\n",
    "# Loss Function: Binary Cross-Entropy (BCE)\n",
    "def bce_loss(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the model\n",
    "    model = EfficientNetFPN(out_channels=1, pretrained=True)\n",
    "\n",
    "    # Example image size: (batch_size=2, channels=3, height=512, width=512)\n",
    "    input_image = torch.randn(2, 3, 512, 512)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_image)\n",
    "    print(\"Output shape: \", output.shape)  # Should output shape (batch_size, 1, 512, 512)\n",
    "\n",
    "    # Example ground truth mask (same shape as output)\n",
    "    target = torch.randn(2, 1, 512, 512)\n",
    "\n",
    "    # Compute BCE loss\n",
    "    loss = bce_loss(output, target)\n",
    "    print(\"Loss: \", loss.item())\n",
    "\n",
    "    # Example optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Backpropagation example\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 87/77564 [03:57<58:38:25,  2.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 234\u001b[0m\n\u001b[0;32m    231\u001b[0m mask_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:/kits23/png_slices/masks/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 194\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(image_dir, mask_dir, epochs, batch_size, lr, num_folds, checkpoint_dir)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m    193\u001b[0m loss \u001b[38;5;241m=\u001b[39m bce_loss(outputs, masks)\n\u001b[1;32m--> 194\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m    197\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset class to handle image and mask loading\n",
    "class KidneySegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, mask_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "        # Collect all case folders (e.g., '00000', '00001', ...)\n",
    "        self.case_folders = os.listdir(image_dir)\n",
    "        self.case_folders = [folder for folder in self.case_folders if os.path.isdir(os.path.join(image_dir, folder))]\n",
    "        \n",
    "        # Calculate total slices across all cases and store slice counts\n",
    "        self.slice_counts = []\n",
    "        for case_id in self.case_folders:\n",
    "            case_image_dir = os.path.join(self.image_dir, case_id)\n",
    "            # Count number of images in the case\n",
    "            num_slices = len([f for f in os.listdir(case_image_dir) if f.endswith('.png')])  # assuming images are .png\n",
    "            self.slice_counts.append(num_slices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        # The length is the total number of slices in all case folders\n",
    "        return sum(self.slice_counts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Determine the case folder and slice number for the given index\n",
    "        cumulative_slices = 0\n",
    "        for i, num_slices in enumerate(self.slice_counts):\n",
    "            cumulative_slices += num_slices\n",
    "            if idx < cumulative_slices:\n",
    "                case_id = self.case_folders[i]\n",
    "                slice_id = idx - (cumulative_slices - num_slices)\n",
    "                break  # Slice indexing\n",
    "        \n",
    "        # Build the paths for the image and mask slice\n",
    "        img_files = sorted([f for f in os.listdir(os.path.join(self.image_dir, case_id)) if f.endswith('.png')])  # Assuming PNG files\n",
    "        mask_files = sorted([f for f in os.listdir(os.path.join(self.mask_dir, case_id)) if f.endswith('.png')])  # Assuming PNG files\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, case_id, img_files[slice_id])\n",
    "        mask_path = os.path.join(self.mask_dir, case_id, mask_files[slice_id])\n",
    "\n",
    "        # Load the image and mask\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB (3 channels)\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Convert to grayscale (1 channel)\n",
    "        \n",
    "        # Apply any transformations if provided\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)  # The mask transformation will not change the number of channels\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "# EfficientNet-B5 Encoder (from torchvision)\n",
    "class EfficientNetB5Encoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EfficientNetB5Encoder, self).__init__()\n",
    "        # Load the pre-trained EfficientNet-B5 model from torchvision\n",
    "        self.encoder = models.efficientnet_b5(pretrained=pretrained)\n",
    "        \n",
    "        # Remove the classification head (fully connected layers) to retain features\n",
    "        self.encoder = nn.Sequential(*list(self.encoder.children())[:-1])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from the encoder\n",
    "        features = self.encoder(x)\n",
    "        return features\n",
    "\n",
    "# FPN Decoder\n",
    "class FPNDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FPNDecoder, self).__init__()\n",
    "        # FPN typically uses several layers to combine features from different scales\n",
    "        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Instead of fixed upsampling, use adaptive upsampling\n",
    "        self.upsample = nn.Upsample(size=(512, 512), mode='bilinear', align_corners=True)  # Adaptive resizing to (512, 512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Decode and combine features from multiple scales\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Upsample the output to match the input size (512x512)\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "\n",
    "# Final model combining EfficientNet-B5 and FPN\n",
    "class EfficientNetFPN(nn.Module):\n",
    "    def __init__(self, out_channels=1, pretrained=True):\n",
    "        super(EfficientNetFPN, self).__init__()\n",
    "        # Encoder: EfficientNetB5\n",
    "        self.encoder = EfficientNetB5Encoder(pretrained=pretrained)\n",
    "        \n",
    "        # Decoder: FPN\n",
    "        self.decoder = FPNDecoder(in_channels=2048, out_channels=out_channels)  # EfficientNet-B5 has 2048 channels in the final layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through encoder and decoder\n",
    "        features = self.encoder(x)\n",
    "        out = self.decoder(features)\n",
    "        return out\n",
    "\n",
    "# Loss Function: Binary Cross-Entropy (BCE)\n",
    "def bce_loss(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)\n",
    "\n",
    "# Training loop with 5-fold cross-validation\n",
    "def train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5,checkpoint_dir='checkpoints'):\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([  # Transformation for the image\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Example mean/std for RGB images\n",
    "    ])\n",
    "    \n",
    "    mask_transform = transforms.Compose([  # Transformation for the mask\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    dataset = KidneySegmentationDataset(image_dir=image_dir, mask_dir=mask_dir, transform=transform, mask_transform=mask_transform)\n",
    "    \n",
    "    # Set up cross-validation\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "    \n",
    "    fold = 1\n",
    "    for train_idx, val_idx in kfold.split(dataset):\n",
    "        print(f\"Training fold {fold}/{num_folds}...\")\n",
    "        \n",
    "        # Split the dataset into training and validation sets for this fold\n",
    "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "        \n",
    "        # Data loaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Initialize model, optimizer, and loss function\n",
    "        model = EfficientNetFPN(out_channels=1, pretrained=True)\n",
    "        \n",
    "        # Check if CUDA is available, else use CPU\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Load checkpoint if it exists\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"fold_{fold}_checkpoint.pth\")\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            print(f\"Resuming from epoch {start_epoch}\")\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            print(\"Starting from scratch\")\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "                # Move to GPU or CPU\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = bce_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    # Move to GPU or CPU\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    # Compute loss\n",
    "                    loss = bce_loss(outputs, masks)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            print(f\"Validation Loss after Epoch {epoch + 1}: {val_loss / len(val_loader)}\")\n",
    "            \n",
    "            # Save checkpoint after each epoch\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "# Set directories for your image and mask data\n",
    "image_dir = \"E:/kits23/png_slices/images/\"\n",
    "mask_dir = \"E:/kits23/png_slices/masks/\"\n",
    "\n",
    "# Train the model\n",
    "train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed!\n",
      "Train cases: 391, Test cases: 98\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(image_dir, mask_dir, output_dir, test_size=0.2):\n",
    "    # Create output directories\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for split in ['train', 'test']:\n",
    "        os.makedirs(os.path.join(output_dir, split, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, split, 'masks'), exist_ok=True)\n",
    "\n",
    "    # Get all case folders\n",
    "    case_folders = os.listdir(image_dir)\n",
    "    case_folders = [folder for folder in case_folders if os.path.isdir(os.path.join(image_dir, folder))]\n",
    "\n",
    "    # Split into train and test\n",
    "    train_cases, test_cases = train_test_split(case_folders, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Helper function to copy files\n",
    "    def copy_files(case_list, split):\n",
    "        for case in case_list:\n",
    "            # Check if the case is already copied\n",
    "            dst_images = os.path.join(output_dir, split, 'images', case)\n",
    "            dst_masks = os.path.join(output_dir, split, 'masks', case)\n",
    "            \n",
    "            if os.path.exists(dst_images) and os.path.exists(dst_masks):\n",
    "                print(f\"Skipping {case}, already copied.\")\n",
    "                continue  # Skip this case\n",
    "            \n",
    "            # Copy images\n",
    "            src_images = os.path.join(image_dir, case)\n",
    "            dst_images = os.path.join(output_dir, split, 'images', case)\n",
    "            shutil.copytree(src_images, dst_images)\n",
    "\n",
    "            # Copy masks\n",
    "            src_masks = os.path.join(mask_dir, case)\n",
    "            dst_masks = os.path.join(output_dir, split, 'masks', case)\n",
    "            shutil.copytree(src_masks, dst_masks)\n",
    "\n",
    "    # Copy data to respective splits\n",
    "    copy_files(train_cases, 'train')\n",
    "    copy_files(test_cases, 'test')\n",
    "\n",
    "    print(\"Dataset split completed!\")\n",
    "    print(f\"Train cases: {len(train_cases)}, Test cases: {len(test_cases)}\")\n",
    "\n",
    "# Usage example\n",
    "image_dir = \"E:/kits23/png_slices/images/\"\n",
    "mask_dir = \"E:/kits23/png_slices/masks/\"\n",
    "output_dir = \"E:/kits23/split_dataset/\"\n",
    "split_dataset(image_dir, mask_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 22/62088 [01:12<56:29:46,  3.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 234\u001b[0m\n\u001b[0;32m    231\u001b[0m mask_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:/kits23/split_dataset/train/masks/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 190\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(image_dir, mask_dir, epochs, batch_size, lr, num_folds, checkpoint_dir)\u001b[0m\n\u001b[0;32m    187\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m    193\u001b[0m loss \u001b[38;5;241m=\u001b[39m bce_loss(outputs, masks)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[1], line 116\u001b[0m, in \u001b[0;36mEfficientNetFPN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# Forward pass through encoder and decoder\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(features)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[1], line 77\u001b[0m, in \u001b[0;36mEfficientNetB5Encoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Extract features from the encoder\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._call_impl at line 1747 (1 times), Module._wrapped_call_impl at line 1736 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[0;32m    166\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\activation.py:432\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2379\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset class to handle image and mask loading\n",
    "class KidneySegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, mask_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "        # Collect all case folders (e.g., '00000', '00001', ...)\n",
    "        self.case_folders = os.listdir(image_dir)\n",
    "        self.case_folders = [folder for folder in self.case_folders if os.path.isdir(os.path.join(image_dir, folder))]\n",
    "        \n",
    "        # Calculate total slices across all cases and store slice counts\n",
    "        self.slice_counts = []\n",
    "        for case_id in self.case_folders:\n",
    "            case_image_dir = os.path.join(self.image_dir, case_id)\n",
    "            # Count number of images in the case\n",
    "            num_slices = len([f for f in os.listdir(case_image_dir) if f.endswith('.png')])  # assuming images are .png\n",
    "            self.slice_counts.append(num_slices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        # The length is the total number of slices in all case folders\n",
    "        return sum(self.slice_counts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Determine the case folder and slice number for the given index\n",
    "        cumulative_slices = 0\n",
    "        for i, num_slices in enumerate(self.slice_counts):\n",
    "            cumulative_slices += num_slices\n",
    "            if idx < cumulative_slices:\n",
    "                case_id = self.case_folders[i]\n",
    "                slice_id = idx - (cumulative_slices - num_slices)\n",
    "                break  # Slice indexing\n",
    "        \n",
    "        # Build the paths for the image and mask slice\n",
    "        img_files = sorted([f for f in os.listdir(os.path.join(self.image_dir, case_id)) if f.endswith('.png')])  # Assuming PNG files\n",
    "        mask_files = sorted([f for f in os.listdir(os.path.join(self.mask_dir, case_id)) if f.endswith('.png')])  # Assuming PNG files\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, case_id, img_files[slice_id])\n",
    "        mask_path = os.path.join(self.mask_dir, case_id, mask_files[slice_id])\n",
    "\n",
    "        # Load the image and mask\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB (3 channels)\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Convert to grayscale (1 channel)\n",
    "        \n",
    "        # Apply any transformations if provided\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)  # The mask transformation will not change the number of channels\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "# EfficientNet-B5 Encoder (from torchvision)\n",
    "class EfficientNetB5Encoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EfficientNetB5Encoder, self).__init__()\n",
    "        # Load the pre-trained EfficientNet-B5 model from torchvision\n",
    "        self.encoder = models.efficientnet_b5(pretrained=pretrained)\n",
    "        \n",
    "        # Remove the classification head (fully connected layers) to retain features\n",
    "        self.encoder = nn.Sequential(*list(self.encoder.children())[:-1])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from the encoder\n",
    "        features = self.encoder(x)\n",
    "        return features\n",
    "\n",
    "# FPN Decoder\n",
    "class FPNDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FPNDecoder, self).__init__()\n",
    "        # FPN typically uses several layers to combine features from different scales\n",
    "        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Instead of fixed upsampling, use adaptive upsampling\n",
    "        self.upsample = nn.Upsample(size=(512, 512), mode='bilinear', align_corners=True)  # Adaptive resizing to (512, 512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Decode and combine features from multiple scales\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Upsample the output to match the input size (512x512)\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "\n",
    "# Final model combining EfficientNet-B5 and FPN\n",
    "class EfficientNetFPN(nn.Module):\n",
    "    def __init__(self, out_channels=1, pretrained=True):\n",
    "        super(EfficientNetFPN, self).__init__()\n",
    "        # Encoder: EfficientNetB5\n",
    "        self.encoder = EfficientNetB5Encoder(pretrained=pretrained)\n",
    "        \n",
    "        # Decoder: FPN\n",
    "        self.decoder = FPNDecoder(in_channels=2048, out_channels=out_channels)  # EfficientNet-B5 has 2048 channels in the final layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through encoder and decoder\n",
    "        features = self.encoder(x)\n",
    "        out = self.decoder(features)\n",
    "        return out\n",
    "\n",
    "# Loss Function: Binary Cross-Entropy (BCE)\n",
    "def bce_loss(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)\n",
    "\n",
    "# Training loop with 5-fold cross-validation\n",
    "def train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5,checkpoint_dir='checkpoints'):\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([  # Transformation for the image\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Example mean/std for RGB images\n",
    "    ])\n",
    "    \n",
    "    mask_transform = transforms.Compose([  # Transformation for the mask\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    dataset = KidneySegmentationDataset(image_dir=image_dir, mask_dir=mask_dir, transform=transform, mask_transform=mask_transform)\n",
    "    \n",
    "    # Set up cross-validation\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "    \n",
    "    fold = 1\n",
    "    for train_idx, val_idx in kfold.split(dataset):\n",
    "        print(f\"Training fold {fold}/{num_folds}...\")\n",
    "        \n",
    "        # Split the dataset into training and validation sets for this fold\n",
    "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "        \n",
    "        # Data loaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Initialize model, optimizer, and loss function\n",
    "        model = EfficientNetFPN(out_channels=1, pretrained=True)\n",
    "        \n",
    "        # Check if CUDA is available, else use CPU\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Load checkpoint if it exists\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"fold_{fold}_checkpoint.pth\")\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            print(f\"Resuming from epoch {start_epoch}\")\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            print(\"Starting from scratch\")\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "                # Move to GPU or CPU\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = bce_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    # Move to GPU or CPU\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    # Compute loss\n",
    "                    loss = bce_loss(outputs, masks)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            print(f\"Validation Loss after Epoch {epoch + 1}: {val_loss / len(val_loader)}\")\n",
    "            \n",
    "            # Save checkpoint after each epoch\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "# Set directories for your image and mask data\n",
    "image_dir = \"E:/kits23/split_dataset/train/images/\"\n",
    "mask_dir = \"E:/kits23/split_dataset/train/masks/\"\n",
    "\n",
    "# Train the model\n",
    "train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAGNA\\AppData\\Local\\Temp\\ipykernel_14992\\168382821.py:171: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"filename 'storages' not found\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 236\u001b[0m\n\u001b[0;32m    233\u001b[0m mask_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:/kits23/split_dataset/train/masks/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 171\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(image_dir, mask_dir, epochs, batch_size, lr, num_folds, checkpoint_dir)\u001b[0m\n\u001b[0;32m    169\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_checkpoint.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(checkpoint_path):\n\u001b[1;32m--> 171\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    173\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:1384\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[0;32m   1385\u001b[0m     opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args\n\u001b[0;32m   1386\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:1611\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1608\u001b[0m     \u001b[38;5;66;03m# legacy_load requires that f has fileno()\u001b[39;00m\n\u001b[0;32m   1609\u001b[0m     \u001b[38;5;66;03m# only if offset is zero we can attempt the legacy tar file loader\u001b[39;00m\n\u001b[0;32m   1610\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1611\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mTarError:\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(f):\n\u001b[0;32m   1614\u001b[0m             \u001b[38;5;66;03m# .zip is used for torch.jit.save and will throw an un-pickling error here\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:1485\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.legacy_load\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deserialized_objects[\u001b[38;5;28mint\u001b[39m(saved_id)]\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m closing(\n\u001b[0;32m   1483\u001b[0m     tarfile\u001b[38;5;241m.\u001b[39mopen(fileobj\u001b[38;5;241m=\u001b[39mf, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mtarfile\u001b[38;5;241m.\u001b[39mPAX_FORMAT)\n\u001b[0;32m   1484\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m tar, mkdtemp() \u001b[38;5;28;01mas\u001b[39;00m tmpdir:\n\u001b[1;32m-> 1485\u001b[0m     \u001b[43mtar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmpdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmpdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorages\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m   1487\u001b[0m         num_storages \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:2081\u001b[0m, in \u001b[0;36mTarFile.extract\u001b[1;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(member, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 2081\u001b[0m     tarinfo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetmember\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmember\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2083\u001b[0m     tarinfo \u001b[38;5;241m=\u001b[39m member\n",
      "File \u001b[1;32mc:\\Users\\PRAGNA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:1803\u001b[0m, in \u001b[0;36mTarFile.getmember\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1801\u001b[0m tarinfo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getmember(name\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tarinfo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tarinfo\n",
      "\u001b[1;31mKeyError\u001b[0m: \"filename 'storages' not found\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset class to handle image and mask loading\n",
    "class KidneySegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, mask_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "        # Collect all case folders (e.g., '00000', '00001', ...)\n",
    "        self.case_folders = os.listdir(image_dir)\n",
    "        self.case_folders = [folder for folder in self.case_folders if os.path.isdir(os.path.join(image_dir, folder))]\n",
    "        \n",
    "        # Calculate total slices across all cases and store slice counts\n",
    "        self.slice_counts = []\n",
    "        for case_id in self.case_folders:\n",
    "            case_image_dir = os.path.join(self.image_dir, case_id)\n",
    "            # Count number of images in the case\n",
    "            num_slices = len([f for f in os.listdir(case_image_dir) if f.endswith('.png')])  # assuming images are .png\n",
    "            self.slice_counts.append(num_slices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        # The length is the total number of slices in all case folders\n",
    "        return sum(self.slice_counts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Determine the case folder and slice number for the given index\n",
    "        cumulative_slices = 0\n",
    "        for i, num_slices in enumerate(self.slice_counts):\n",
    "            cumulative_slices += num_slices\n",
    "            if idx < cumulative_slices:\n",
    "                case_id = self.case_folders[i]\n",
    "                slice_id = idx - (cumulative_slices - num_slices)\n",
    "                break  # Slice indexing\n",
    "        \n",
    "        # Build the paths for the image and mask slice\n",
    "        img_files = sorted([f for f in os.listdir(os.path.join(self.image_dir, case_id)) if f.endswith('.png')])  # Assuming PNG files\n",
    "        mask_files = sorted([f for f in os.listdir(os.path.join(self.mask_dir, case_id)) if f.endswith('.png')])  # Assuming PNG files\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, case_id, img_files[slice_id])\n",
    "        mask_path = os.path.join(self.mask_dir, case_id, mask_files[slice_id])\n",
    "\n",
    "        # Load the image and mask\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB (3 channels)\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Convert to grayscale (1 channel)\n",
    "        \n",
    "        # Apply any transformations if provided\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)  # The mask transformation will not change the number of channels\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "# EfficientNet-B5 Encoder (from torchvision)\n",
    "class EfficientNetB5Encoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EfficientNetB5Encoder, self).__init__()\n",
    "        # Load the pre-trained EfficientNet-B5 model from torchvision\n",
    "        self.encoder = models.efficientnet_b5(pretrained=pretrained)\n",
    "        \n",
    "        # Remove the classification head (fully connected layers) to retain features\n",
    "        self.encoder = nn.Sequential(*list(self.encoder.children())[:-1])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from the encoder\n",
    "        features = self.encoder(x)\n",
    "        return features\n",
    "\n",
    "# FPN Decoder\n",
    "class FPNDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FPNDecoder, self).__init__()\n",
    "        # FPN typically uses several layers to combine features from different scales\n",
    "        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Instead of fixed upsampling, use adaptive upsampling\n",
    "        self.upsample = nn.Upsample(size=(512, 512), mode='bilinear', align_corners=True)  # Adaptive resizing to (512, 512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Decode and combine features from multiple scales\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Upsample the output to match the input size (512x512)\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "\n",
    "# Final model combining EfficientNet-B5 and FPN\n",
    "class EfficientNetFPN(nn.Module):\n",
    "    def __init__(self, out_channels=1, pretrained=True):\n",
    "        super(EfficientNetFPN, self).__init__()\n",
    "        # Encoder: EfficientNetB5\n",
    "        self.encoder = EfficientNetB5Encoder(pretrained=pretrained)\n",
    "        \n",
    "        # Decoder: FPN\n",
    "        self.decoder = FPNDecoder(in_channels=2048, out_channels=out_channels)  # EfficientNet-B5 has 2048 channels in the final layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through encoder and decoder\n",
    "        features = self.encoder(x)\n",
    "        out = self.decoder(features)\n",
    "        return out\n",
    "\n",
    "# Loss Function: Binary Cross-Entropy (BCE)\n",
    "def bce_loss(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)\n",
    "\n",
    "# Training loop with 5-fold cross-validation\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5, checkpoint_dir='checkpoints'):\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize the dataset\n",
    "    dataset = KidneySegmentationDataset(image_dir=image_dir, mask_dir=mask_dir, transform=transform, mask_transform=mask_transform)\n",
    "\n",
    "    # Set up cross-validation\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset), start=1):\n",
    "        print(f\"Training fold {fold}/{num_folds}...\")\n",
    "\n",
    "        # Split dataset\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        # Data loaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize model, optimizer, and loss function\n",
    "        model = EfficientNetFPN(out_channels=1, pretrained=True)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Load checkpoint if exists\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"fold_{fold}_checkpoint.pth\")\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            start_batch = checkpoint['batch']\n",
    "            print(f\"Resuming from epoch {start_epoch + 1}, batch {start_batch + 1}\")\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            start_batch = 0\n",
    "            print(\"Starting from scratch\")\n",
    "            \n",
    "            \n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "\n",
    "            for batch_idx, (images, masks) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"), start=start_batch):\n",
    "                # Skip already processed batches\n",
    "                if batch_idx < start_batch:\n",
    "                    continue\n",
    "\n",
    "                # Move to device\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = bce_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Save progress after each batch\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'batch': batch_idx,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, checkpoint_path)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = bce_loss(outputs, masks)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            print(f\"Validation Loss after Epoch {epoch + 1}: {val_loss / len(val_loader)}\")\n",
    "\n",
    "            # Reset start_batch for the next epoch\n",
    "            start_batch = 0\n",
    "\n",
    "\n",
    "# Set directories for your image and mask data\n",
    "image_dir = \"E:/kits23/split_dataset/train/images/\"\n",
    "mask_dir = \"E:/kits23/split_dataset/train/masks/\"\n",
    "\n",
    "# Train the model\n",
    "train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "\n",
    "# Dataset class\n",
    "class KidneySegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, mask_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.case_folders = [\n",
    "            folder for folder in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, folder))\n",
    "        ]\n",
    "        self.slice_counts = [\n",
    "            len([f for f in os.listdir(os.path.join(image_dir, case)) if f.endswith('.png')])\n",
    "            for case in self.case_folders\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.slice_counts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cumulative_slices = 0\n",
    "        for i, num_slices in enumerate(self.slice_counts):\n",
    "            cumulative_slices += num_slices\n",
    "            if idx < cumulative_slices:\n",
    "                case_id = self.case_folders[i]\n",
    "                slice_id = idx - (cumulative_slices - num_slices)\n",
    "                break\n",
    "        \n",
    "        img_files = sorted([f for f in os.listdir(os.path.join(self.image_dir, case_id)) if f.endswith('.png')])\n",
    "        mask_files = sorted([f for f in os.listdir(os.path.join(self.mask_dir, case_id)) if f.endswith('.png')])\n",
    "        img_path = os.path.join(self.image_dir, case_id, img_files[slice_id])\n",
    "        mask_path = os.path.join(self.mask_dir, case_id, mask_files[slice_id])\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        return img, mask\n",
    "\n",
    "# Model components\n",
    "class EfficientNetB5Encoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EfficientNetB5Encoder, self).__init__()\n",
    "        self.encoder = models.efficientnet_b5(weights=\"DEFAULT\" if pretrained else None)\n",
    "        self.encoder = nn.Sequential(*list(self.encoder.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class FPNDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FPNDecoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        self.upsample = nn.Upsample(size=(512, 512), mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        return self.upsample(x)\n",
    "\n",
    "class EfficientNetFPN(nn.Module):\n",
    "    def __init__(self, out_channels=1, pretrained=True):\n",
    "        super(EfficientNetFPN, self).__init__()\n",
    "        self.encoder = EfficientNetB5Encoder(pretrained=pretrained)\n",
    "        self.decoder = FPNDecoder(in_channels=2048, out_channels=out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        return self.decoder(features)\n",
    "\n",
    "# Loss function\n",
    "def bce_loss(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)\n",
    "\n",
    "# Atomic save function\n",
    "def atomic_save(data, file_path):\n",
    "    temp_path = tempfile.NamedTemporaryFile(delete=False, dir=os.path.dirname(file_path)).name\n",
    "    torch.save(data, temp_path)\n",
    "    os.replace(temp_path, file_path)\n",
    "\n",
    "# Training loop\n",
    "def train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5, checkpoint_dir='checkpoints'):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    mask_transform = transforms.ToTensor()\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    dataset = KidneySegmentationDataset(image_dir=image_dir, mask_dir=mask_dir, transform=transform, mask_transform=mask_transform)\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset), start=1):\n",
    "        print(f\"Training fold {fold}/{num_folds}...\")\n",
    "        train_loader = DataLoader(Subset(dataset, train_idx), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(Subset(dataset, val_idx), batch_size=batch_size, shuffle=False)\n",
    "        model = EfficientNetFPN(out_channels=1, pretrained=True).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"fold_{fold}_checkpoint.pth\")\n",
    "\n",
    "        start_epoch, start_batch = 0, 0\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            try:\n",
    "                checkpoint = torch.load(checkpoint_path)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                start_epoch = checkpoint['epoch']\n",
    "                start_batch = checkpoint['batch']\n",
    "                print(f\"Resuming from epoch {start_epoch + 1}, batch {start_batch + 1}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load checkpoint for fold {fold}: {e}\")\n",
    "                print(\"Starting from scratch for this fold.\")\n",
    "\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for batch_idx, (images, masks) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"), start=start_batch):\n",
    "                images, masks = images.to(\"cuda\"), masks.to(\"cuda\")\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = bce_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                atomic_save({'epoch': epoch, 'batch': batch_idx, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, checkpoint_path)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "            val_loss = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images, masks = images.to(\"cuda\"), masks.to(\"cuda\")\n",
    "                    val_loss += bce_loss(model(images), masks).item()\n",
    "            print(f\"Validation Loss after Epoch {epoch + 1}: {val_loss / len(val_loader)}\")\n",
    "            start_batch = 0\n",
    "\n",
    "# Set directories for image and mask data\n",
    "image_dir = \"E:/kits23/split_dataset/train/images/\"\n",
    "mask_dir = \"E:/kits23/split_dataset/train/masks/\"\n",
    "train_model(image_dir, mask_dir, epochs=50, batch_size=2, lr=0.001, num_folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "class SliceLevelDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, slice_metadata, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.slice_metadata = slice_metadata  # List of tuples (case_folder, slice_idx)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slice_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_folder, slice_idx = self.slice_metadata[idx]\n",
    "        \n",
    "        # Load the specific slice\n",
    "        image_path = os.path.join(self.image_dir, case_folder, f\"slice_{slice_idx}.nii.gz\")\n",
    "        mask_path = os.path.join(self.mask_dir, case_folder, f\"slice_{slice_idx}.nii.gz\")\n",
    "        \n",
    "        image = nib.load(image_path).get_fdata()\n",
    "        mask = nib.load(mask_path).get_fdata()\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "        mask_tensor = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image_tensor)\n",
    "            mask_tensor = self.transform(mask_tensor)\n",
    "        \n",
    "        return image_tensor, mask_tensor\n",
    "\n",
    "\n",
    "def create_slice_metadata(image_dir):\n",
    "    \"\"\"\n",
    "    Create a metadata list where each entry corresponds to (case_folder, slice_idx).\n",
    "    \"\"\"\n",
    "    metadata = []\n",
    "    case_folders = sorted(os.listdir(image_dir))\n",
    "    \n",
    "    for case_folder in case_folders:\n",
    "        slice_files = sorted(os.listdir(os.path.join(image_dir, case_folder)))\n",
    "        for slice_file in slice_files:\n",
    "            slice_idx = slice_file.split('_')[1].replace('.nii.gz', '')  # Assuming naming like 'slice_000.nii.gz'\n",
    "            metadata.append((case_folder, slice_idx))\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "\n",
    "def split_slices_kfold(slice_metadata, k=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the slices into K-Folds while ensuring case-level integrity.\n",
    "    \"\"\"\n",
    "    # Extract unique case identifiers\n",
    "    unique_cases = sorted({case for case, _ in slice_metadata})\n",
    "    case_to_slices = {case: [] for case in unique_cases}\n",
    "    \n",
    "    for case, slice_idx in slice_metadata:\n",
    "        case_to_slices[case].append(slice_idx)\n",
    "    \n",
    "    # K-Fold splitting based on cases\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    case_indices = np.arange(len(unique_cases))\n",
    "    \n",
    "    folds = []\n",
    "    for train_indices, val_indices in kf.split(case_indices):\n",
    "        train_cases = [unique_cases[i] for i in train_indices]\n",
    "        val_cases = [unique_cases[i] for i in val_indices]\n",
    "        \n",
    "        train_slices = [(case, idx) for case in train_cases for idx in case_to_slices[case]]\n",
    "        val_slices = [(case, idx) for case in val_cases for idx in case_to_slices[case]]\n",
    "        \n",
    "        folds.append((train_slices, val_slices))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_dir = 'E:/kits23/2d_slices/images/'\n",
    "mask_dir = 'E:/kits23/2d_slices/masks/'\n",
    "\n",
    "# Step 1: Create slice-level metadata\n",
    "slice_metadata = create_slice_metadata(image_dir)\n",
    "\n",
    "# Step 2: Perform K-Fold splitting\n",
    "folds = split_slices_kfold(slice_metadata, k=5)\n",
    "\n",
    "# Step 3: Create datasets and dataloaders for a specific fold\n",
    "fold_idx = 0  # For the first fold\n",
    "train_slices, val_slices = folds[fold_idx]\n",
    "\n",
    "train_dataset = SliceLevelDataset(image_dir, mask_dir, train_slices)\n",
    "val_dataset = SliceLevelDataset(image_dir, mask_dir, val_slices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Now you can use train_loader and val_loader for training!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
